\documentclass[../main.tex]{subfiles}
\graphicspath{{./images/}}

\begin{document}

\section{Introduction}
The aim of this project is to test different approaches and algorithms with the purpose of detecting objects in dense environments. Note that by detecting I mean discerning if a certain object is present in an environment, and if it is, find its position. The type of dense environment that will be used for this project will be a simulation of a supermarket shelf, where objects are close together in a relatively confined space. To that effect, a testbed with groceries will be built. The environment will be captured with a depth camera, able to output both a 3D point cloud and a 2D image. Hence, the approach is twofold: computer vision algorithms for the 2D image and point cloud processing algorithms for the point cloud data.

Since the aim of this work is to provide a comprehensive study of the most prominent approaches one may take to tackle the task of detecting objects in a scene, instead of going too much in depth into one single research topic the goal is to provide many working solutions using both well established and state of the art techniques. Hence, this work is focused on providing the widest array of solutions possible while being thorough and comprehensive and properly justifying the decisions made in the process.

The thesis is divided into 4 main parts\footnote{That is, apart from the normative ones, like \emph{Future Work}, \emph{Conclusions}, etc.}: Section \ref{sec:methodology_and_tooling} \emph{Methodology and tooling}, where assumptions about the conditions under which the work is done are stated, and the testbench is presented. The tooling part lists, on the one hand, the potential depth cameras in the market that could have been used in the project along with their defining characteristics, and the one that has been finally chosen. On the other hand, all libraries and utilities used for the project are presented (namely the computer vision libraries used). Section \ref{sec:2D_approach} \emph{2D approach to object detection} is conceptually divided in two parts: the first one focuses on the difficulties of creating a dataset of 2D RGB images and their corresponding annotations. The issue is tackled by programming a full-fledged Graphical User Interface with the ability to open images and label them in several ways, along with tools to change their appearance need be. The second part focuses on applying the most prominent computer vision algorithms in the literature to detect the objects, ordering the methods by complexity. It begins with the most simple one, template matching, all the way to neural networks. Section \ref{sec:3D_approach} \emph{3D approach to object detection} explains the steps needed to process point cloud data first, and then goes on to develop the approaches taken to detect objects in said data\footnote{As mentioned before, it has to be noted that the approaches one could take (both in Sections \ref{sec:2D_approach} and \ref{sec:3D_approach}) are only a representative portion of the ones available, which are many, many more. The attempt of this work is to provide the seemingly most prominent and promising ones.}. Finally, Section \ref{sec:2D_3D_approaches} \emph{Combining the 2D and 3D approaches} combines both approaches, with the attempt to use the best performing algorithms of both approaches into one single ``recognition pipeline".


% HABLAR DE COMO SERAN LAS HERRAMIENTAS Y EL PORQUE SE USAN. DECIR QUE PESE A QUE MUCHAS COSAS ESTAN IMPLEMENTADAS, SE HARA UNA INTRODUCCION TEORICA DE SUS FUNDAMENTOS.

% Even though this may change later, the idea is to use the OpenCV library for the computer vision set of algorithms. Preferably, the Python wrappings will be used for faster testing. For the point cloud processing, the library that will be used is PCL (Point Cloud Library, created by Radu B. Rusu), in C++. The depth camera that will be used is yet to be decided, but chances are that I will use an Intel RealSense D435. Depending on the time and results obtained as the project evolves (and if the need arises) convolutional neural networks may be implemented. Were that to be the case, the library that I would use is TensorFlow. The reason behind these decisions is the fact that I already have experience using both the libraries and the camera. 
 
\end{document}